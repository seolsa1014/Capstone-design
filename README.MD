1.  이미지 데이터이 CNN.
2.  데이터 전처리
    이미지 해싱을 통해 중복되는 이미지는 제거

3.  유해 이미지의 기준.

    1. 성인물( but 데이터셋 저장 및 결과 검증등의 제한이 커 주제에서 제외)
    2. 폭력 콘텐츠
    3. 유혈 이미지
    4. 위험 오브젝트( 총, 칼 , 담배, 마약)
    5. 혐오 제스쳐
    6. 자살 묘사

4.  오브젝트 감지후, 결과 정보를 텍스로 저장.오브젝트의 레이블과 박스를 보고, 적절히 검열

5.  최종보고서는 직접 사진들을 구하거나 찍어 모델에 적용시켜보고. 최종 보고서에 작성, 영상도 자동으로 모델적용이
    가능한점을 들어 gif형식의 움짤도 검출 가능함을 어필 and 실행파일 만들기

https://github.com/poori-nuna/HOD-Benchmark-Dataset
에서 데이터셋 차용 및 코드 참조를 많이 했습니다. 이에 감사를 표합니다.
(순수 학습용 제작 목적의 참고이며, 다른 어떠한 부적잘한 목적의 사용이 절대 없음을 밝힙니다.)
